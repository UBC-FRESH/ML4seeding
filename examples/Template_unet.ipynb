{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. import the necessery libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras import regularizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. load and split the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import imageio \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "path =''\n",
    "# image_path = os.path.join(path,'../input/semantic-drone-dataset/dataset/semantic_drone_dataset/original_images/')\n",
    "# mask_path = os.path.join(path,'../input/semantic-drone-dataset/dataset/semantic_drone_dataset/label_images_semantic/')\n",
    "image_path = './data/semantic_drone_dataset/dataset/semantic_drone_dataset/original_images/'\n",
    "mask_path = './data/semantic_drone_dataset/dataset/semantic_drone_dataset/label_images_semantic/'\n",
    "\n",
    "image_list = sorted([\n",
    "    f for f in os.listdir(image_path)\n",
    "    if os.path.isfile(os.path.join(image_path, f))\n",
    "    and not f.startswith('.')                         # ignore hidden\n",
    "    and f.lower().endswith(('.jpg', '.jpeg', '.png')) # images\n",
    "])\n",
    "\n",
    "mask_list = sorted([\n",
    "    f for f in os.listdir(mask_path)\n",
    "    if os.path.isfile(os.path.join(mask_path, f))\n",
    "    and not f.startswith('.')                         # ignore hidden, e.g. .ipynb_checkpoints\n",
    "    and f.lower().endswith(('.png', '.jpg', '.jpeg')) # masks\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 2️⃣ Keep only filenames that have BOTH image and mask (match by ID = name without extension)\n",
    "image_ids = {os.path.splitext(f)[0] for f in image_list}\n",
    "mask_ids  = {os.path.splitext(f)[0] for f in mask_list}\n",
    "common_ids = sorted(image_ids & mask_ids)\n",
    "\n",
    "image_list = [f for f in image_list if os.path.splitext(f)[0] in common_ids]\n",
    "mask_list  = [f for f in mask_list  if os.path.splitext(f)[0] in common_ids]\n",
    "\n",
    "\n",
    "\n",
    "# 3️⃣ Optionally prepend full paths (if you want paths instead of just filenames)\n",
    "image_list = [os.path.join(image_path, f) for f in image_list]\n",
    "mask_list  = [os.path.join(mask_path,  f) for f in mask_list]\n",
    "\n",
    "\n",
    "# image_list = sorted(image_list)\n",
    "# mask_list = sorted(mask_list)\n",
    "\n",
    "train_image_list = image_list[:390]\n",
    "train_mask_list = mask_list[:390]\n",
    "\n",
    "validation_image_list = image_list[390:400]\n",
    "validation_mask_list = mask_list[390:400]\n",
    "\n",
    "print(sorted(os.listdir(image_path))[:10])\n",
    "print(sorted(os.listdir(mask_path))[:10])\n",
    "\n",
    "\n",
    "print(\"number of train images is : {} \".format(len(train_image_list)))\n",
    "print(\"number of train masks is : {} \".format(len(train_mask_list)))\n",
    "\n",
    "print(\"number of train images is : {} \".format(len(validation_image_list)))\n",
    "print(\"number of train masks is : {} \".format(len(validation_mask_list)))\n",
    "\n",
    "print(image_list[0])\n",
    "print(mask_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. explore some images :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 # you can chose any index \n",
    "img  = imageio.imread(train_image_list[n])\n",
    "print(img.shape)\n",
    "mask = imageio.imread(train_mask_list[n])\n",
    "print(mask.shape)\n",
    "\n",
    "# now let's plot \n",
    "fig ,arr  = plt.subplots(1,2,figsize=(15,10))\n",
    "arr[0].imshow(img)\n",
    "arr[0].set_title('Original Image')\n",
    "arr[1].imshow(mask)\n",
    "arr[1].set_title('Mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.constant(train_image_list)\n",
    "train_masks = tf.constant(train_mask_list)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images,train_masks))\n",
    "for image,mask in train_dataset.take(1) : \n",
    "    print(image)\n",
    "    print(mask)\n",
    "    \n",
    "validation_images = tf.constant(validation_image_list)\n",
    "validation_masks = tf.constant(validation_mask_list)\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_images,validation_masks))\n",
    "for image,mask in validation_dataset.take(1) : \n",
    "    print(image)\n",
    "    print(mask)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. preprocessing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(image_path,mask_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img,channels=3)\n",
    "    img = tf.image.convert_image_dtype(img,tf.float32) #this do the same as dividing by 255 to set the values between 0 and 1 (normalization)\n",
    "    \n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask,channels=3)\n",
    "    mask = tf.math.reduce_max(mask,axis=-1,keepdims=True)\n",
    "    return img , mask\n",
    "\n",
    "def preprocess(image,mask) : \n",
    "    input_image = tf.image.resize(image,(96,128),method='nearest')\n",
    "    input_mask = tf.image.resize(mask,(96,128),method='nearest')\n",
    "    \n",
    "    return input_image , input_mask\n",
    "\n",
    "train_image_ds = train_dataset.map(process_path) # apply the preprocces_path function to our train_dataset\n",
    "print(train_image_ds)\n",
    "train_processed_image_ds = train_image_ds.map(preprocess) # apply the preprocess function to our train_dataset\n",
    "\n",
    "validation_image_ds = validation_dataset.map(process_path) # apply the preprocces_path function to our validation_dataset\n",
    "print(validation_image_ds)\n",
    "validation_processed_image_ds = validation_image_ds.map(preprocess) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.  Define The Conv Block For The Contracting Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n",
    "    \n",
    "    conv = Conv2D(n_filters, \n",
    "                  kernel_size = 3,     \n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.HeNormal())(inputs)\n",
    "    conv = Conv2D(n_filters, \n",
    "                  kernel_size = 3, \n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n",
    "   \n",
    "    \n",
    "\n",
    "    if dropout_prob > 0:\n",
    "        conv = Dropout(dropout_prob)(conv)\n",
    "        \n",
    "    if max_pooling:\n",
    "        next_layer = MaxPooling2D(pool_size=(2,2))(conv)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        next_layer = conv\n",
    "        \n",
    "    skip_connection = conv\n",
    "    \n",
    "    return next_layer, skip_connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Define the upsampling block for the expanding path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling_block(expansive_input, contractive_input, n_filters=32):\n",
    "    \n",
    "    up = Conv2DTranspose(\n",
    "                 n_filters,  \n",
    "                 kernel_size = 3,\n",
    "                 strides=(2,2),\n",
    "                 padding='same')(expansive_input)\n",
    "    \n",
    "    merge = concatenate([up, contractive_input], axis=3)\n",
    "    conv = Conv2D(n_filters,  \n",
    "                 kernel_size = 3,   \n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer=tf.keras.initializers.HeNormal())(merge)\n",
    "    conv = Conv2D(n_filters,  \n",
    "                 kernel_size = 3,  \n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n",
    "    \n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Finally! ,  we will Define the unet model \n",
    "## which composes of a set of conv blocks and upsampling blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_size=(96, 128, 3), n_filters=32, n_classes=23):\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # contracting path\n",
    "    cblock1 = conv_block(inputs, n_filters, dropout_prob=0.4)\n",
    "    cblock2 = conv_block(cblock1[0], 2*n_filters, dropout_prob=0.4)\n",
    "    cblock3 = conv_block(cblock2[0], 4*n_filters, dropout_prob=0.4)\n",
    "    cblock4 = conv_block(cblock3[0], 8*n_filters, dropout_prob=0.45) \n",
    "    cblock5 = conv_block(cblock4[0],16*n_filters, dropout_prob=0.4, max_pooling=None)     \n",
    "    \n",
    "    # expanding path\n",
    "    ublock6 = upsampling_block(cblock5[0], cblock4[1],  8 * n_filters)\n",
    "    ublock7 = upsampling_block(ublock6, cblock3[1],  n_filters*4)\n",
    "    ublock8 = upsampling_block(ublock7,cblock2[1] , n_filters*2)\n",
    "    ublock9 = upsampling_block(ublock8,cblock1[1],  n_filters)\n",
    "\n",
    "    conv9 = Conv2D(n_filters,\n",
    "                 3,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(ublock9)\n",
    "    \n",
    "    conv10 = Conv2D(n_classes, kernel_size=1, padding='same')(conv9)  \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 96\n",
    "img_width = 128\n",
    "num_channels = 3\n",
    "\n",
    "unet = unet_model((img_height, img_width, num_channels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Our model is ready !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "VAL_SUBSPLITS = 5\n",
    "BUFFER_SIZE = 390\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# train\n",
    "train_processed_image_ds.batch(BATCH_SIZE)\n",
    "train_dataset = train_processed_image_ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "print(train_processed_image_ds.element_spec)\n",
    "\n",
    "# validation\n",
    "validation_processed_image_ds.batch(BATCH_SIZE)\n",
    "validation_dataset = validation_processed_image_ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "print(validation_processed_image_ds.element_spec)\n",
    " \n",
    "\n",
    "model_history = unet.fit(train_dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(dataset=None, num=1):\n",
    "    \"\"\"\n",
    "    Displays the first image of each of the num batches\n",
    "    \"\"\"\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = unet.predict(image)\n",
    "            display([image[0], mask[0], create_mask(pred_mask)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "             create_mask(unet.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----- training_dataset results---------\")\n",
    "show_predictions(train_dataset, 6)\n",
    "print(\"----- validation_dataset results---------\")\n",
    "show_predictions(validation_dataset, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "print(\"Unet Model Evaluation: \")\n",
    "unet.evaluate(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf220)",
   "language": "python",
   "name": "tf220"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
